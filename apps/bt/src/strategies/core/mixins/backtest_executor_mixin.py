"""
ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡ŒãƒŸãƒƒã‚¯ã‚¹ã‚¤ãƒ³

YamlConfigurableStrategyç”¨ã®ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œãƒ»çµæœç”Ÿæˆæ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ã€‚
"""

from typing import TYPE_CHECKING, Any, Dict, Optional, Tuple, cast

import pandas as pd
import vectorbt as vbt

from src.models.allocation import AllocationInfo

CostParams = Tuple[float, float]
GroupedPortfolioInputs = tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]

if TYPE_CHECKING:
    from .protocols import StrategyProtocol

# ã‚»ã‚¯ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ã«ä¾å­˜ã™ã‚‹ã‚·ã‚°ãƒŠãƒ«å
_SECTOR_SIGNALS = ("sector_strength_ranking", "sector_rotation_phase", "sector_volatility_regime")

# ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã«ä¾å­˜ã™ã‚‹ã‚·ã‚°ãƒŠãƒ«åï¼ˆã‚»ã‚¯ã‚¿ãƒ¼å¼·åº¦ãƒ»ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã¯TOPIXå¯¾æ¯”è¨ˆç®—ã§å¿…è¦ï¼‰
_BENCHMARK_SIGNALS = (
    "beta", "index_daily_change", "index_macd_histogram",
    "sector_strength_ranking", "sector_rotation_phase",
)


def _is_signal_enabled(params: Any, signal_name: str) -> bool:
    """ã‚·ã‚°ãƒŠãƒ«ãŒæœ‰åŠ¹ã‹ãƒã‚§ãƒƒã‚¯"""
    if params is None:
        return False
    signal = getattr(params, signal_name, None)
    if signal is None:
        return False
    return getattr(signal, "enabled", False)


def _any_signal_enabled(
    entry_params: Any, exit_params: Any, signal_names: tuple[str, ...]
) -> str | None:
    """æŒ‡å®šã‚·ã‚°ãƒŠãƒ«ç¾¤ã®ã„ãšã‚Œã‹ãŒæœ‰åŠ¹ãªã‚‰ã€ãã®ã‚·ã‚°ãƒŠãƒ«åã‚’è¿”ã™ã€‚ç„¡åŠ¹ãªã‚‰Noneã€‚"""
    for name in signal_names:
        if _is_signal_enabled(entry_params, name):
            return f"entry_filter_params.{name}"
        if _is_signal_enabled(exit_params, name):
            return f"exit_trigger_params.{name}"
    return None


class BacktestExecutorMixin:
    """ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œæ©Ÿèƒ½ãƒŸãƒƒã‚¯ã‚¹ã‚¤ãƒ³"""

    def _find_signal_for_data_requirement(
        self: "StrategyProtocol",
        requirement: str,
    ) -> str | None:
        """æŒ‡å®šãƒ‡ãƒ¼ã‚¿è¦ä»¶ãŒå¿…è¦ãªæœ‰åŠ¹ã‚·ã‚°ãƒŠãƒ«ã‚’æ¢ç´¢ã—ã¦ãƒ‘ã‚¹ã‚’è¿”ã™ã€‚"""
        from src.strategies.signals.registry import SIGNAL_REGISTRY

        entry_params = getattr(self, "entry_filter_params", None)
        exit_params = getattr(self, "exit_trigger_params", None)

        for signal_def in SIGNAL_REGISTRY:
            if not any(
                req == requirement or req.startswith(f"{requirement}:")
                for req in signal_def.data_requirements
            ):
                continue

            if entry_params is not None and signal_def.enabled_checker(entry_params):
                return f"entry_filter_params.{signal_def.param_key}"
            if exit_params is not None and signal_def.enabled_checker(exit_params):
                return f"exit_trigger_params.{signal_def.param_key}"

        return None

    def _should_load_sector_data(self: "StrategyProtocol") -> bool:
        """ã‚»ã‚¯ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ã®ãƒ­ãƒ¼ãƒ‰ãŒå¿…è¦ã‹ãƒã‚§ãƒƒã‚¯"""
        entry_params = getattr(self, "entry_filter_params", None)
        exit_params = getattr(self, "exit_trigger_params", None)

        matched = _any_signal_enabled(entry_params, exit_params, _SECTOR_SIGNALS)
        if matched:
            self._log(f"ã‚»ã‚¯ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿å¿…è¦: {matched}.enabled", "debug")
        return matched is not None

    def _should_load_benchmark(self: "StrategyProtocol") -> bool:
        """ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã®ãƒ­ãƒ¼ãƒ‰ãŒå¿…è¦ã‹ãƒã‚§ãƒƒã‚¯"""
        entry_params = getattr(self, "entry_filter_params", None)
        exit_params = getattr(self, "exit_trigger_params", None)

        matched = _any_signal_enabled(entry_params, exit_params, _BENCHMARK_SIGNALS)
        if matched:
            self._log(f"ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å¿…è¦: {matched}.enabled", "debug")
            return True

        self._log("ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ä¸è¦: è©²å½“ã‚·ã‚°ãƒŠãƒ«ãŒæœ‰åŠ¹åŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“", "debug")
        return False

    def _should_load_margin_data(self: "StrategyProtocol") -> bool:
        """ä¿¡ç”¨æ®‹é«˜ãƒ‡ãƒ¼ã‚¿ã®ãƒ­ãƒ¼ãƒ‰ãŒå¿…è¦ã‹ãƒã‚§ãƒƒã‚¯ã€‚"""
        matched = self._find_signal_for_data_requirement("margin")
        if matched:
            self._log(f"ä¿¡ç”¨æ®‹é«˜ãƒ‡ãƒ¼ã‚¿å¿…è¦: {matched}", "debug")
            return True

        self._log("ä¿¡ç”¨æ®‹é«˜ãƒ‡ãƒ¼ã‚¿ä¸è¦: ä¾å­˜ã‚·ã‚°ãƒŠãƒ«ãŒæœ‰åŠ¹åŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“", "debug")
        return False

    def _should_load_statements_data(self: "StrategyProtocol") -> bool:
        """è²¡å‹™è«¸è¡¨ãƒ‡ãƒ¼ã‚¿ã®ãƒ­ãƒ¼ãƒ‰ãŒå¿…è¦ã‹ãƒã‚§ãƒƒã‚¯ã€‚"""
        matched = self._find_signal_for_data_requirement("statements")
        if matched:
            self._log(f"è²¡å‹™è«¸è¡¨ãƒ‡ãƒ¼ã‚¿å¿…è¦: {matched}", "debug")
            return True

        self._log("è²¡å‹™è«¸è¡¨ãƒ‡ãƒ¼ã‚¿ä¸è¦: ä¾å­˜ã‚·ã‚°ãƒŠãƒ«ãŒæœ‰åŠ¹åŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“", "debug")
        return False

    def _calculate_cost_params(self: "StrategyProtocol") -> CostParams:
        """æ¯”ä¾‹æ‰‹æ•°æ–™ã¨ã‚¹ãƒªãƒƒãƒšãƒ¼ã‚¸ã‚’è¨ˆç®—ã™ã‚‹ã€‚

        Returns:
            (effective_fees, effective_slippage) ã®ã‚¿ãƒ—ãƒ«ã€‚
            feesã«ã¯spreadãƒ»å€Ÿæ ªè²»ç”¨ã‚’å«ã¿ã€slippageã¯åˆ†é›¢ã—ã¦è¿”ã™ã€‚
        """
        effective_fees = self.fees + self.spread
        if getattr(self, "direction", "longonly") in ["shortonly", "both"]:
            effective_fees += self.borrow_fee
        return effective_fees, self.slippage

    def _set_grouped_portfolio_inputs_cache(
        self: "StrategyProtocol",
        close_data: pd.DataFrame,
        all_entries: pd.DataFrame,
        all_exits: pd.DataFrame,
    ) -> None:
        """ç¬¬2æ®µéšæœ€é©åŒ–ç”¨ã«çµ±åˆãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªå…¥åŠ›ã‚’ä¿æŒã™ã‚‹ã€‚"""
        setattr(
            self,
            "_grouped_portfolio_inputs_cache",
            (close_data, all_entries, all_exits),
        )

    def _clear_grouped_portfolio_inputs_cache(self: "StrategyProtocol") -> None:
        """çµ±åˆãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªå…¥åŠ›ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã™ã‚‹ã€‚"""
        setattr(self, "_grouped_portfolio_inputs_cache", None)

    def _get_grouped_portfolio_inputs_cache(
        self: "StrategyProtocol",
    ) -> GroupedPortfolioInputs | None:
        """ä¿æŒæ¸ˆã¿ã®çµ±åˆãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªå…¥åŠ›ã‚’å–å¾—ã™ã‚‹ã€‚"""
        cached = getattr(self, "_grouped_portfolio_inputs_cache", None)
        if cached is None:
            return None

        if not isinstance(cached, tuple) or len(cached) != 3:
            return None

        close_data, all_entries, all_exits = cached
        if not (
            isinstance(close_data, pd.DataFrame)
            and isinstance(all_entries, pd.DataFrame)
            and isinstance(all_exits, pd.DataFrame)
        ):
            return None

        return cast(GroupedPortfolioInputs, cached)

    def _create_grouped_portfolio(
        self: "StrategyProtocol",
        close_data: pd.DataFrame,
        all_entries: pd.DataFrame,
        all_exits: pd.DataFrame,
        allocation_pct: Optional[float] = None,
    ) -> vbt.Portfolio:
        """çµ±åˆãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã‚’ä½œæˆã™ã‚‹ã€‚"""
        effective_fees, effective_slippage = self._calculate_cost_params()

        # ãƒ”ãƒ©ãƒŸãƒƒãƒ‡ã‚£ãƒ³ã‚°æ©Ÿèƒ½ï¼ˆç¾åœ¨æœªå®Ÿè£…ã€å¸¸ã«Falseï¼‰
        pyramid_enabled = False

        if len(self.stock_codes) > 1:
            # ãƒãƒ«ãƒã‚¢ã‚»ãƒƒãƒˆæˆ¦ç•¥: å…±æœ‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ—ãƒ¼ãƒ« + é©åˆ‡ãªã‚µã‚¤ã‚ºé…åˆ†
            if allocation_pct is not None:
                # 2æ®µéšæœ€é©åŒ–: æœ€é©åŒ–ã•ã‚ŒãŸé…åˆ†ç‡ã‚’ä½¿ç”¨
                allocation_per_asset = allocation_pct
                self._log(f"âš¡ æœ€é©åŒ–é…åˆ†ä½¿ç”¨: {allocation_per_asset:.1%}", "info")
            else:
                # é€šå¸¸å®Ÿè¡Œ: å‡ç­‰é…åˆ†ç‡ã‚’ä½¿ç”¨
                allocation_per_asset = 1.0 / len(self.stock_codes)  # å‡ç­‰é…åˆ†ç‡

            self._log(
                f"ğŸ’° è³‡é‡‘é…åˆ†: ç·é¡{self.initial_cash:,}å††ï¼ˆå…±æœ‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ—ãƒ¼ãƒ«ï¼‰",
                "info",
            )
            self._log(
                f"ğŸ“Š å„éŠ˜æŸ„é…åˆ†ç‡: {allocation_per_asset:.1%} ({allocation_per_asset * 100:.1f}%)",
                "info",
            )

            portfolio_kwargs = dict(
                close=close_data,
                entries=all_entries,
                exits=all_exits,
                direction=getattr(
                    self, "direction", "longonly"
                ),  # ğŸ†• è¿½åŠ : å–å¼•æ–¹å‘è¨­å®š
                init_cash=self.initial_cash,  # ğŸ”§ ä¿®æ­£: å…±æœ‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ—ãƒ¼ãƒ«å…¨ä½“
                size=allocation_per_asset,  # ğŸ†• è¿½åŠ : å„éŠ˜æŸ„ã¸ã®é…åˆ†ç‡
                size_type="percent",  # ğŸ†• è¿½åŠ : ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆæŒ‡å®š
                fees=effective_fees,
                slippage=effective_slippage,  # ç´„å®šä¾¡æ ¼ã‚·ãƒ•ãƒˆï¼ˆãƒã‚¤ãƒ†ã‚£ãƒ–å¯¾å¿œï¼‰
                cash_sharing=True,  # è³‡é‡‘å…±æœ‰æœ‰åŠ¹
                group_by=True,  # çµ±åˆãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ª
                accumulate=pyramid_enabled,  # ğŸ†• è¿½åŠ : ãƒ”ãƒ©ãƒŸãƒƒãƒ‡ã‚£ãƒ³ã‚°å¯¾å¿œ
                call_seq="auto",  # ğŸ†• è¿½åŠ : å®Ÿè¡Œé †åºæœ€é©åŒ–
                freq="D",
            )
            if self.max_exposure is not None:
                portfolio_kwargs["max_size"] = self.max_exposure

            return vbt.Portfolio.from_signals(**portfolio_kwargs)  # type: ignore[arg-type]

        # ã‚·ãƒ³ã‚°ãƒ«éŠ˜æŸ„æˆ¦ç•¥: å¾“æ¥é€šã‚Š
        portfolio_kwargs = dict(
            close=close_data,
            entries=all_entries,
            exits=all_exits,
            direction=getattr(
                self, "direction", "longonly"
            ),  # ğŸ†• è¿½åŠ : å–å¼•æ–¹å‘è¨­å®š
            init_cash=self.initial_cash,
            fees=effective_fees,
            slippage=effective_slippage,  # ç´„å®šä¾¡æ ¼ã‚·ãƒ•ãƒˆï¼ˆãƒã‚¤ãƒ†ã‚£ãƒ–å¯¾å¿œï¼‰
            cash_sharing=self.cash_sharing,
            group_by=True if self.cash_sharing else None,
            accumulate=pyramid_enabled,  # ğŸ†• è¿½åŠ : ãƒ”ãƒ©ãƒŸãƒƒãƒ‡ã‚£ãƒ³ã‚°å¯¾å¿œ
            freq="D",
        )
        if self.max_exposure is not None:
            portfolio_kwargs["max_size"] = self.max_exposure

        return vbt.Portfolio.from_signals(**portfolio_kwargs)  # type: ignore[arg-type]

    def run_multi_backtest_from_cached_signals(
        self: "StrategyProtocol",
        allocation_pct: float,
    ) -> vbt.Portfolio:
        """ä¿æŒæ¸ˆã¿ã‚·ã‚°ãƒŠãƒ«ã‚’å†åˆ©ç”¨ã—ã¦é…åˆ†ã®ã¿å¤‰æ›´ã—ã¦å†å®Ÿè¡Œã™ã‚‹ã€‚"""
        cached = self._get_grouped_portfolio_inputs_cache()
        if cached is None:
            raise ValueError("çµ±åˆãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªå…¥åŠ›ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒå­˜åœ¨ã—ã¾ã›ã‚“")

        close_data, all_entries, all_exits = cached
        self._log("âš¡ ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ¸ˆã¿ã‚·ã‚°ãƒŠãƒ«ã‚’å†åˆ©ç”¨ã—ã¦ç¬¬2æ®µéšã‚’å®Ÿè¡Œ", "info")
        portfolio = self._create_grouped_portfolio(
            close_data=close_data,
            all_entries=all_entries,
            all_exits=all_exits,
            allocation_pct=allocation_pct,
        )
        self.combined_portfolio = portfolio
        return portfolio

    def run_multi_backtest(
        self: "StrategyProtocol",
        allocation_pct: Optional[float] = None,
    ) -> Tuple[vbt.Portfolio, Optional[pd.DataFrame]]:
        """
        è¤‡æ•°éŠ˜æŸ„ãƒ»Relative Modeã®ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ

        Args:
            allocation_pct: é…åˆ†ç‡ä¸Šæ›¸ãï¼ˆNoneã®å ´åˆã¯å‡ç­‰é…åˆ†ï¼‰

        Returns:
            Tuple[vbt.Portfolio, Optional[pd.DataFrame]]:
                - ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
                - ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚·ã‚°ãƒŠãƒ«DataFrameï¼ˆçµ±åˆãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®å ´åˆã®ã¿ã€å€‹åˆ¥ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®å ´åˆã¯Noneï¼‰
        """
        if allocation_pct is None:
            # æ–°è¦ã®ç¬¬1æ®µéšå®Ÿè¡Œæ™‚ã¯ä»¥å‰ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ç„¡åŠ¹åŒ–
            self._clear_grouped_portfolio_inputs_cache()

        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
        use_group_by = self.group_by

        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ï¼ˆRelative Modeã‹ã©ã†ã‹ã§åˆ†å²ï¼‰
        multi_data_dict = None
        relative_data_dict = None
        execution_data_dict = None

        # Relative Modeåˆ¤å®šã¨ãƒ­ã‚®ãƒ³ã‚°
        mode_info = []
        if self.relative_mode:
            mode_info.append("Relative Mode")
        mode_str = " + ".join(mode_info) if mode_info else "Standard"

        self._log(f"{self.__class__.__name__} {mode_str} å®Ÿè¡Œé–‹å§‹", "info")
        self._log(
            f"éŠ˜æŸ„æ•°: {len(self.stock_codes)}, Group By: {use_group_by}",
            "debug",
        )

        # ã‚»ã‚¯ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚·ã‚°ãƒŠãƒ«ç”¨ãƒ»ä¸€åº¦ã ã‘ãƒ­ãƒ¼ãƒ‰ï¼‰
        sector_data = None
        stock_sector_mapping = None

        if self._should_load_sector_data():
            self._log(
                "ã‚»ã‚¯ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ä¾å­˜ã‚·ã‚°ãƒŠãƒ«æœ‰åŠ¹ - ã‚»ã‚¯ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰é–‹å§‹",
                "info",
            )
            try:
                from src.data.loaders.sector_loaders import (
                    get_stock_sector_mapping,
                    load_all_sector_indices,
                )

                sector_data = load_all_sector_indices(
                    self.dataset, self.start_date, self.end_date
                )
                stock_sector_mapping = get_stock_sector_mapping(self.dataset)

                if sector_data:
                    self._log(
                        f"âœ… ã‚»ã‚¯ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰å®Œäº†: {len(sector_data)}ã‚»ã‚¯ã‚¿ãƒ¼",
                        "info",
                    )
                else:
                    self._log(
                        "âš ï¸  ã‚»ã‚¯ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ãŒç©º - ã‚»ã‚¯ã‚¿ãƒ¼ã‚·ã‚°ãƒŠãƒ«ãŒã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã™",
                        "warning",
                    )
            except Exception as e:
                self._log(
                    f"âš ï¸  ã‚»ã‚¯ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e} - ã‚»ã‚¯ã‚¿ãƒ¼ã‚·ã‚°ãƒŠãƒ«ãŒã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã™",
                    "warning",
                )

        # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ä¾å­˜ã‚·ã‚°ãƒŠãƒ«ãŒæœ‰åŠ¹ãªå ´åˆã¯ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰
        if self._should_load_benchmark():
            self._log(
                "ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ä¾å­˜ã‚·ã‚°ãƒŠãƒ«æœ‰åŠ¹ - ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰é–‹å§‹",
                "info",
            )
            try:
                self.load_benchmark_data()
                if self.benchmark_data is not None and not self.benchmark_data.empty:
                    self._log(
                        f"âœ… ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰å®Œäº†: {len(self.benchmark_data)}ãƒ¬ã‚³ãƒ¼ãƒ‰",
                        "info",
                    )
                else:
                    self._log(
                        "âš ï¸  ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ãŒç©ºã¾ãŸã¯None - ä¾å­˜ã‚·ã‚°ãƒŠãƒ«ãŒã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã™",
                        "warning",
                    )
            except Exception as e:
                self._log(
                    f"âš ï¸  ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e} - ä¾å­˜ã‚·ã‚°ãƒŠãƒ«ãŒã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã™",
                    "warning",
                )

        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        if self.relative_mode:
            # Relative Mode: ç›¸å¯¾ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚·ã‚°ãƒŠãƒ«ç”¨ï¼‰ã¨å®Ÿéš›ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ï¼ˆå®Ÿè¡Œç”¨ï¼‰ã‚’åˆ†é›¢
            relative_data_dict, execution_data_dict = self.load_relative_data()
            self._log(
                "Relative Mode - ã‚·ã‚°ãƒŠãƒ«ç”¨ç›¸å¯¾ãƒ‡ãƒ¼ã‚¿ã¨å®Ÿè¡Œç”¨å®Ÿãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™å®Œäº†", "info"
            )
        else:
            # Standard Mode: é€šå¸¸ã®ãƒãƒ«ãƒã‚¢ã‚»ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿
            multi_data_dict = self.load_multi_data()

        # ğŸ”§ ãƒ‡ãƒ¼ã‚¿åŒæœŸ: ãƒ­ãƒ¼ãƒ‰æˆåŠŸã—ãŸéŠ˜æŸ„ã®ã¿ã«çµã‚Šè¾¼ã¿
        if self.relative_mode and execution_data_dict is not None:
            loaded_codes = set(execution_data_dict.keys())
        elif multi_data_dict is not None:
            loaded_codes = set(multi_data_dict.keys())
        else:
            loaded_codes = set()

        requested_codes = set(self.stock_codes)
        missing_codes = requested_codes - loaded_codes

        if missing_codes:
            self._log(
                f"âš ï¸ {len(missing_codes)}éŠ˜æŸ„ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {sorted(missing_codes)[:10]}{'...' if len(missing_codes) > 10 else ''}",
                "warning",
            )
            # stock_codesã‚’å®Ÿéš›ã«ãƒ­ãƒ¼ãƒ‰ã§ããŸéŠ˜æŸ„ã«æ›´æ–°
            self.stock_codes = [code for code in self.stock_codes if code in loaded_codes]

        if not self.stock_codes:
            raise ValueError("æœ‰åŠ¹ãªéŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

        # å„éŠ˜æŸ„ã®ãƒ‡ãƒ¼ã‚¿ã¨ã‚·ã‚°ãƒŠãƒ«ã‚’çµ±åˆ
        data_dict = {}
        entries_dict = {}
        exits_dict = {}

        for stock_code in self.stock_codes:
            # ã‚»ã‚¯ã‚¿ãƒ¼ã‚·ã‚°ãƒŠãƒ«ç”¨: å½“è©²éŠ˜æŸ„ã®ã‚»ã‚¯ã‚¿ãƒ¼åã‚’å–å¾—
            stock_sector_name = None
            if stock_sector_mapping and stock_code in stock_sector_mapping:
                stock_sector_name = stock_sector_mapping[stock_code]

            if (
                self.relative_mode
                and relative_data_dict is not None
                and execution_data_dict is not None
            ):
                # Relative Mode: ç›¸å¯¾ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã§ã‚·ã‚°ãƒŠãƒ«ç”Ÿæˆã€å®Ÿéš›ã®ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã§ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªå®Ÿè¡Œ
                signal_data = cast(
                    pd.DataFrame,
                    relative_data_dict[stock_code]["daily"],  # type: ignore[index]
                )  # ã‚·ã‚°ãƒŠãƒ«ç”¨ç›¸å¯¾ãƒ‡ãƒ¼ã‚¿
                execution_data = cast(
                    pd.DataFrame,
                    execution_data_dict[stock_code]["daily"],  # type: ignore[index]
                )  # å®Ÿè¡Œç”¨å®Ÿãƒ‡ãƒ¼ã‚¿

                # margin_dataã‚’å–å¾—ï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
                margin_data = None
                if (
                    self.include_margin_data
                    and "margin_daily" in execution_data_dict[stock_code]  # type: ignore[index]
                ):
                    margin_data = cast(
                        pd.DataFrame,
                        execution_data_dict[stock_code]["margin_daily"],  # type: ignore[index]
                    )

                # statements_dataã®å–å¾—
                statements_data = None
                if (
                    self.include_statements_data
                    and "statements_daily" in execution_data_dict[stock_code]  # type: ignore[index]
                ):
                    statements_data = cast(
                        pd.DataFrame,
                        execution_data_dict[stock_code]["statements_daily"],  # type: ignore[index]
                    )

                # ç›¸å¯¾ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã§ã‚·ã‚°ãƒŠãƒ«ç”Ÿæˆï¼ˆå®Ÿä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã‚‚æ¸¡ã™ï¼‰
                signals = self.generate_multi_signals(
                    stock_code,
                    signal_data,
                    margin_data=margin_data,
                    statements_data=statements_data,
                    execution_data=execution_data,  # å®Ÿä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã‚’æ¸¡ã™ï¼ˆÎ²å€¤ãƒ»å£²è²·ä»£é‡‘ã‚·ã‚°ãƒŠãƒ«ç”¨ï¼‰
                    sector_data=sector_data,
                    stock_sector_name=stock_sector_name,
                )
                entries, exits = signals.entries, signals.exits

                # å®Ÿéš›ã®ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªå®Ÿè¡Œç”¨ã«è¨­å®š
                stock_data = execution_data

                self._log(
                    f"{stock_code} (Relative): ç›¸å¯¾ãƒ‡ãƒ¼ã‚¿ã§ã‚·ã‚°ãƒŠãƒ«ç”Ÿæˆ, å®Ÿãƒ‡ãƒ¼ã‚¿ã§å®Ÿè¡Œï¼ˆÎ²å€¤ãƒ»å£²è²·ä»£é‡‘ã¯å®Ÿä¾¡æ ¼ä½¿ç”¨ï¼‰",
                    "debug",
                )

            elif multi_data_dict is not None:
                # é€šå¸¸ã®ã‚·ãƒ³ã‚°ãƒ«TFå‡¦ç†
                stock_data = multi_data_dict[stock_code]["daily"]

                # margin_dataã‚’å–å¾—ï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
                margin_data = None
                if (
                    self.include_margin_data
                    and "margin_daily" in multi_data_dict[stock_code]
                ):
                    margin_data = multi_data_dict[stock_code]["margin_daily"]

                # statements_dataã®å–å¾—
                statements_data = None
                if (
                    self.include_statements_data
                    and "statements_daily" in multi_data_dict[stock_code]
                ):
                    statements_data = multi_data_dict[stock_code]["statements_daily"]

                signals = self.generate_multi_signals(
                    stock_code,
                    stock_data,
                    margin_data=margin_data,
                    statements_data=statements_data,
                    sector_data=sector_data,
                    stock_sector_name=stock_sector_name,
                )
                entries, exits = signals.entries, signals.exits
            else:
                raise ValueError("Data loading failed - no valid data source available")

            data_dict[stock_code] = stock_data
            entries_dict[stock_code] = entries
            exits_dict[stock_code] = exits

            # ğŸ” DEBUG: å„éŠ˜æŸ„ã®ã‚·ã‚°ãƒŠãƒ«ç”ŸæˆçŠ¶æ³ã‚’è©³ç´°å‡ºåŠ›
            entries_count = entries.sum()
            exits_count = exits.sum()
            data_length = len(stock_data)

            self._log(
                f"{stock_code}: è²·ã„{entries_count}ä»¶, å£²ã‚Š{exits_count}ä»¶ (ãƒ‡ãƒ¼ã‚¿{data_length}æ—¥åˆ†)",
                "info",
            )

            # ã•ã‚‰ã«è©³ç´°ãªãƒ‡ãƒãƒƒã‚°æƒ…å ±
            if entries_count == 0:
                self._log(f"âš ï¸  {stock_code}: è²·ã„ã‚·ã‚°ãƒŠãƒ«ãŒ1ä»¶ã‚‚ã‚ã‚Šã¾ã›ã‚“", "warning")
            elif entries_count < 5:
                self._log(
                    f"ğŸ“Š {stock_code}: è²·ã„ã‚·ã‚°ãƒŠãƒ«ãŒå°‘æ•°({entries_count}ä»¶)ã§ã™",
                    "info",
                )

        if use_group_by:
            # çµ±åˆãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®å ´åˆ
            # VectorBTãƒã‚¤ãƒ†ã‚£ãƒ–çµ±åˆãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªä½œæˆ
            try:
                # ãƒ‡ãƒ¼ã‚¿çµ±åˆï¼ˆVectorBTå¯¾å¿œã®ãŸã‚çµ‚å€¤ã®ã¿ä½¿ç”¨ï¼‰
                close_data = pd.DataFrame(
                    {
                        stock_code: data["Close"]
                        for stock_code, data in data_dict.items()
                    }
                )

                # ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒ»ã‚¨ã‚°ã‚¸ãƒƒãƒˆã‚·ã‚°ãƒŠãƒ«çµ±åˆ
                # pandas 2.2.0+ FutureWarningå›é¿ã®ãŸã‚ã€ã‚ªãƒ—ã‚·ãƒ§ãƒ³è¨­å®šã‚’ä½¿ç”¨
                with pd.option_context("future.no_silent_downcasting", True):
                    all_entries = (
                        pd.DataFrame(entries_dict)
                        .fillna(False)
                        .infer_objects(copy=False)
                        .astype(bool)
                    )
                    all_exits = (
                        pd.DataFrame(exits_dict)
                        .fillna(False)
                        .infer_objects(copy=False)
                        .astype(bool)
                    )

                # ãƒ‡ãƒ¼ã‚¿å‹ç¢ºèªã¨ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
                close_data = close_data.astype(float)

                # ğŸ” DEBUG: çµ±åˆå¾Œã®ã‚·ã‚°ãƒŠãƒ«çµ±è¨ˆ
                total_entries = all_entries.sum().sum()
                total_exits = all_exits.sum().sum()

                self._log(
                    f"ãƒ‡ãƒ¼ã‚¿çµ±åˆå®Œäº† - Close: {close_data.shape}, Entries: {all_entries.shape}, Exits: {all_exits.shape}",
                    "debug",
                )
                self._log(
                    f"ğŸš€ çµ±åˆã‚·ã‚°ãƒŠãƒ«çµ±è¨ˆ - å…¨è²·ã„ã‚·ã‚°ãƒŠãƒ«: {total_entries}ä»¶, å…¨å£²ã‚Šã‚·ã‚°ãƒŠãƒ«: {total_exits}ä»¶",
                    "info",
                )

                # å„éŠ˜æŸ„ã”ã¨ã®ã‚·ã‚°ãƒŠãƒ«æ•°ã‚‚ãƒã‚§ãƒƒã‚¯
                entries_per_stock = all_entries.sum()
                active_stocks = (entries_per_stock > 0).sum()
                self._log(
                    f"ğŸ“ˆ ã‚¢ã‚¯ãƒ†ã‚£ãƒ–éŠ˜æŸ„æ•°: {active_stocks}/{len(self.stock_codes)}éŠ˜æŸ„",
                    "info",
                )

                # åŒæ™‚ä¿æœ‰ãƒã‚¸ã‚·ãƒ§ãƒ³æ•°ã®ä¸Šé™ï¼ˆç°¡æ˜“: æ—¥æ¬¡ã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼æ•°ã‚’åˆ¶é™ï¼‰
                if self.max_concurrent_positions:
                    all_entries = self._limit_entries_per_day(
                        all_entries, self.max_concurrent_positions
                    )

                self._set_grouped_portfolio_inputs_cache(
                    close_data=close_data,
                    all_entries=all_entries,
                    all_exits=all_exits,
                )

                portfolio = self._create_grouped_portfolio(
                    close_data=close_data,
                    all_entries=all_entries,
                    all_exits=all_exits,
                    allocation_pct=allocation_pct,
                )

                self.combined_portfolio = portfolio
                self._log("çµ±åˆãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªä½œæˆå®Œäº†", "info")

                # ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã¨ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚·ã‚°ãƒŠãƒ«DataFrameã‚’è¿”å´
                return portfolio, all_entries
            except Exception as e:
                self._log(f"ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªä½œæˆã‚¨ãƒ©ãƒ¼: {e}", "error")
                raise RuntimeError(f"Failed to create portfolio: {e}")
        else:
            self._clear_grouped_portfolio_inputs_cache()
            # å€‹åˆ¥ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®å ´åˆï¼ˆãƒ”ãƒ©ãƒŸãƒƒãƒ‡ã‚£ãƒ³ã‚°ã¯æœªå®Ÿè£…ï¼‰
            pyramid_enabled = False
            portfolio = self._create_individual_portfolios(
                data_dict, entries_dict, exits_dict, pyramid_enabled
            )
            # å€‹åˆ¥ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®å ´åˆã¯all_entriesã¯None
            return portfolio, None

    def _create_individual_portfolios(
        self,
        data_dict: Dict[str, pd.DataFrame],
        entries_dict: Dict[str, pd.Series],
        exits_dict: Dict[str, pd.Series],
        pyramid_enabled: bool = False,
    ) -> vbt.Portfolio:
        """
        å€‹åˆ¥ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã‚’ä½œæˆ

        Args:
            data_dict: éŠ˜æŸ„åˆ¥ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
            entries_dict: éŠ˜æŸ„åˆ¥ã‚¨ãƒ³ãƒˆãƒªã‚·ã‚°ãƒŠãƒ«
            exits_dict: éŠ˜æŸ„åˆ¥ã‚¨ã‚°ã‚¸ãƒƒãƒˆã‚·ã‚°ãƒŠãƒ«

        Returns:
            vbt.Portfolio: å€‹åˆ¥ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ª
        """
        close_data = pd.DataFrame({k: v["Close"] for k, v in data_dict.items()})
        entries_data = pd.DataFrame(entries_dict)
        exits_data = pd.DataFrame(exits_dict)

        # DataFrameã®å‹ã‚’é©åˆ‡ã«è¨­å®š
        entries_data = entries_data.fillna(False).infer_objects(copy=False).astype(bool)
        exits_data = exits_data.fillna(False).infer_objects(copy=False).astype(bool)

        if self.max_concurrent_positions:
            entries_data = self._limit_entries_per_day(
                entries_data, self.max_concurrent_positions
            )

        effective_fees, effective_slippage = self._calculate_cost_params()

        portfolio_kwargs = dict(
            close=close_data,
            entries=entries_data,
            exits=exits_data,
            direction=getattr(self, "direction", "longonly"),  # ğŸ†• è¿½åŠ : å–å¼•æ–¹å‘è¨­å®š
            init_cash=self.initial_cash,
            fees=effective_fees,
            slippage=effective_slippage,  # ç´„å®šä¾¡æ ¼ã‚·ãƒ•ãƒˆï¼ˆãƒã‚¤ãƒ†ã‚£ãƒ–å¯¾å¿œï¼‰
            group_by=None,  # å€‹åˆ¥ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ª
            accumulate=pyramid_enabled,  # ğŸ†• è¿½åŠ : ãƒ”ãƒ©ãƒŸãƒƒãƒ‡ã‚£ãƒ³ã‚°å¯¾å¿œ
            freq="D",
        )
        if self.max_exposure is not None:
            portfolio_kwargs["max_size"] = self.max_exposure

        portfolio = vbt.Portfolio.from_signals(**portfolio_kwargs)  # type: ignore[arg-type]

        self.portfolio = portfolio
        self._log("å€‹åˆ¥ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªä½œæˆå®Œäº†", "info")
        return portfolio

    @staticmethod
    def _limit_entries_per_day(
        entries: pd.DataFrame, max_positions: int
    ) -> pd.DataFrame:
        """æ—¥æ¬¡ã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼æ•°ã‚’ä¸Šé™ã§åˆ¶é™ï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        if max_positions <= 0:
            return entries

        limited = entries.copy()
        for idx, row in entries.iterrows():
            if row.sum() <= max_positions:
                continue
            true_cols = row[row].index.tolist()
            drop_cols = true_cols[max_positions:]
            if drop_cols:
                limited.loc[idx, drop_cols] = False  # type: ignore[index]
        return limited

    def run_optimized_backtest(
        self, group_by: Optional[bool] = None
    ) -> Tuple[vbt.Portfolio, vbt.Portfolio, AllocationInfo]:
        """
        2æ®µéšKellyåŸºæº–æœ€é©åŒ–ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ

        Args:
            group_by: çµ±åˆãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã¨ã—ã¦æ‰±ã†ã‹ï¼ˆNoneã®å ´åˆã¯self.group_byã‚’ä½¿ç”¨ï¼‰

        Returns:
            Tuple[vbt.Portfolio, vbt.Portfolio, AllocationInfo]:
                - ç¬¬1æ®µéšçµæœ
                - ç¬¬2æ®µéšæœ€é©åŒ–çµæœ
                - KellyåŸºæº–çµ±è¨ˆæƒ…å ±
        """
        self._log("ğŸ¯ KellyåŸºæº–2æ®µéšæœ€é©åŒ–ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆé–‹å§‹", "info")

        try:
            # KellyåŸºæº–ã«ã‚ˆã‚‹2æ®µéšæœ€é©åŒ–
            (
                initial_portfolio,
                final_portfolio,
                optimized_allocation,
                stats,
                all_entries,
            ) = self.run_optimized_backtest_kelly(
                kelly_fraction=self.kelly_fraction,
                min_allocation=self.min_allocation,
                max_allocation=self.max_allocation,
            )

            # KellyåŸºæº–ã®è©³ç´°çµ±è¨ˆæƒ…å ±ã‚’è¿”ã™
            allocation_info = AllocationInfo(
                method="kelly",
                allocation=optimized_allocation,
                win_rate=stats.get("win_rate", 0.0),
                avg_win=stats.get("avg_win", 0.0),
                avg_loss=stats.get("avg_loss", 0.0),
                total_trades=stats.get("total_trades", 0),
                full_kelly=stats.get("kelly", 0.0),
                kelly_fraction=self.kelly_fraction,
            )

            # all_entriesã‚’ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å¤‰æ•°ã¨ã—ã¦ä¿å­˜ï¼ˆStrategyFactoryã§ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ã«ã™ã‚‹ï¼‰
            self.all_entries = all_entries

            return initial_portfolio, final_portfolio, allocation_info

        except Exception as e:
            self._log(f"KellyåŸºæº–2æ®µéšæœ€é©åŒ–ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}", "error")
            raise RuntimeError(f"KellyåŸºæº–2æ®µéšæœ€é©åŒ–ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œå¤±æ•—: {e}")
